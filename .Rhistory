alpha_sum_sd = sd(rowSums(pred$alpha_predictions))
)
cat("\nPrediction type:", pred_type, "\n")
cat("  MAE:", round(mae, 4), "\n")
cat("  RMSE:", round(rmse, 4), "\n")
cat("  Mean Aitchison distance:", round(aitchison, 4), "\n")
cat("  Avg log-likelihood:", round(loglik, 4), "\n")
}
# Cleanup
cleanup_distributed_forest(model)
cat("\nModel cleaned up.\n")
}
return(results)
}
visualize_results <- function(results) {
# Convert results to data frame
results_df <- do.call(rbind, lapply(names(results), function(name) {
r <- results[[name]]
data.frame(
config = r$config,
store_samples = r$store_samples,
method = r$method,
prediction_type = r$prediction_type,
train_time = r$train_time,
pred_time = r$pred_time,
mae = r$mae,
rmse = r$rmse,
mean_aitchison = r$mean_aitchison,
avg_loglik = r$avg_loglik,
alpha_sum_mean = r$alpha_sum_mean,
alpha_sum_sd = r$alpha_sum_sd,
stringsAsFactors = FALSE
)
}))
# Create comparison plots
par(mfrow = c(2, 3))
# 1. MAE comparison
barplot(
results_df$mae,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Mean Absolute Error",
ylab = "MAE",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 2. RMSE comparison
barplot(
results_df$rmse,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Root Mean Squared Error",
ylab = "RMSE",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 3. Aitchison distance
barplot(
results_df$mean_aitchison,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Mean Aitchison Distance",
ylab = "Aitchison Distance",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 4. Log-likelihood
barplot(
results_df$avg_loglik,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Average Log-Likelihood",
ylab = "Log-Likelihood",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 5. Training time
barplot(
results_df$train_time,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method),
main = "Training Time",
ylab = "Seconds",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 6. Prediction time
barplot(
results_df$pred_time,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method),
main = "Prediction Time",
ylab = "Seconds",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
par(mfrow = c(1, 1))
return(results_df)
}
# Generate data
cat("Generating data...\n")
data_sim <- simulate_dirichlet_data(n_samples = 1000, n_features = 10,
n_categories = 3, seed = 42)
data_split <- split_data(data_sim$X, data_sim$Y, train_ratio = 0.8)
# Run comparison
cat("\nStarting comparison...\n")
results <- compare_configurations(
data = data_split,
n_trees = 100,
n_cores = 3,
seed = 123
)
library(DirichletForestParallel)
# Function to simulate Dirichlet-distributed data
simulate_dirichlet_data <- function(n_samples, n_features = 10, n_categories = 3, seed) {
set.seed(seed)
# Initialize feature matrix
X <- matrix(0, nrow = n_samples, ncol = n_features)
colnames(X) <- paste0("X", 1:n_features)
# Generate categorical and continuous features
for (col in 1:n_features) {
X[, col] <- sample(1:5, n_samples, replace = TRUE)  # Categorical features
}
X[, 1] <- runif(n_samples)  # Continuous feature
X[, 2] <- runif(n_samples)
X[, 3] <- runif(n_samples)
# Initialize alpha matrix
alpha <- matrix(0, nrow = n_samples, ncol = n_categories)
# Function to assign values based on quantiles
assign_based_on_quantile <- function(x, quantiles = c(0.3, 0.6, 0.8), values = c(2, 3, 4)) {
q <- quantile(x, probs = quantiles)
result <- rep(1, length(x))
result[x < q[1]] <- values[1]
result[x >= q[1] & x < q[2]] <- values[2]
result[x >= q[2] & x <= q[3]] <- values[3]
return(result)
}
# Assign alpha values based on transformations of X
alpha[, 1] <- assign_based_on_quantile(2 + 2 * sin(X[, 1]) + X[, 2]^3)
alpha[, 2] <- assign_based_on_quantile(1 + 2.5 * exp(X[, 3]) + X[, 1]^2)
alpha[, 3] <- assign_based_on_quantile(1 + (1 + X[, 2])^2 + X[, 3]^4)
# Function to generate Dirichlet-like samples
dirichlet_like_sample <- function(alpha_row) {
samples <- sapply(alpha_row, function(a) max(0.001, rnorm(1, mean = max(0.1, a), sd = 0.5)))
return(samples / sum(samples))
}
# Generate Y values
Y <- t(apply(alpha, 1, dirichlet_like_sample))
return(list(X = X, Y = Y, alpha = alpha))
}
# Function to split data into training and test sets
split_data <- function(X, Y, train_ratio = 0.8) {
n_samples <- nrow(X)
n_train <- floor(train_ratio * n_samples)
indices <- sample(1:n_samples, n_samples)
train_indices <- indices[1:n_train]
test_indices <- indices[(n_train + 1):n_samples]
return(list(
X_train = X[train_indices, ],
Y_train = Y[train_indices, ],
X_test = X[test_indices, ],
Y_test = Y[test_indices, ]
))
}
# Mean Absolute Error for compositional data
mae_compositional <- function(y_true, y_pred) {
return(mean(abs(y_true - y_pred)))
}
# Root Mean Squared Error
rmse_compositional <- function(y_true, y_pred) {
return(sqrt(mean((y_true - y_pred)^2)))
}
# Aitchison distance (proper metric for compositional data)
aitchison_distance <- function(y_true, y_pred) {
# Add small constant to avoid log(0)
y_true <- y_true + 1e-10
y_pred <- y_pred + 1e-10
# Geometric mean
geom_mean_true <- exp(rowMeans(log(y_true)))
geom_mean_pred <- exp(rowMeans(log(y_pred)))
# Centered log-ratio transform
clr_true <- log(y_true / geom_mean_true)
clr_pred <- log(y_pred / geom_mean_pred)
# Euclidean distance in CLR space
return(sqrt(rowSums((clr_true - clr_pred)^2)))
}
# Mean Aitchison distance
mean_aitchison <- function(y_true, y_pred) {
return(mean(aitchison_distance(y_true, y_pred)))
}
# Log-likelihood for Dirichlet distribution
dirichlet_loglik <- function(y_true, alpha_pred) {
n <- nrow(y_true)
k <- ncol(y_true)
loglik <- 0
for (i in 1:n) {
alpha <- alpha_pred[i, ]
y <- y_true[i, ]
# Add small constant to avoid numerical issues
y <- pmax(y, 1e-10)
alpha <- pmax(alpha, 1e-10)
# Dirichlet log-likelihood
loglik <- loglik + lgamma(sum(alpha)) - sum(lgamma(alpha)) +
sum((alpha - 1) * log(y))
}
return(loglik / n)  # Average log-likelihood
}
compare_configurations <- function(data, n_trees = 100, n_cores = 3, seed = 123) {
# Define configurations
configs <- expand.grid(
store_samples = c(FALSE, TRUE),
method = c("mom", "mle"),
stringsAsFactors = FALSE
)
# Add prediction type (mean vs alpha-derived)
prediction_types <- c("mean", "alpha_derived")
results <- list()
for (i in 1:nrow(configs)) {
config_name <- paste0(
"store_", configs$store_samples[i],
"_method_", configs$method[i]
)
cat("\n========================================\n")
cat("Configuration:", config_name, "\n")
cat("========================================\n")
# Train model
cat("Training model...\n")
start_time <- Sys.time()
model <- DirichletForest_distributed(
X = data$X_train,
Y = data$Y_train,
B = n_trees,
store_samples = configs$store_samples[i],
method = configs$method[i],
n_cores = n_cores,
seed = seed
)
train_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat("Training time:", round(train_time, 2), "seconds\n")
# Predict
cat("Making predictions...\n")
start_time <- Sys.time()
pred <- predict_distributed_forest(
distributed_forest = model,
X_new = data$X_test,
method = configs$method[i]
)
pred_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat("Prediction time:", round(pred_time, 2), "seconds\n")
# Evaluate both prediction types
for (pred_type in prediction_types) {
result_name <- paste0(config_name, "_pred_", pred_type)
if (pred_type == "mean") {
y_pred <- pred$mean_predictions
} else {
# Derive mean from alpha: mean_j = alpha_j / sum(alpha)
y_pred <- pred$alpha_predictions / rowSums(pred$alpha_predictions)
}
# Calculate metrics
mae <- mae_compositional(data$Y_test, y_pred)
rmse <- rmse_compositional(data$Y_test, y_pred)
aitchison <- mean_aitchison(data$Y_test, y_pred)
loglik <- dirichlet_loglik(data$Y_test, pred$alpha_predictions)
results[[result_name]] <- list(
config = config_name,
store_samples = configs$store_samples[i],
method = configs$method[i],
prediction_type = pred_type,
train_time = train_time,
pred_time = pred_time,
mae = mae,
rmse = rmse,
mean_aitchison = aitchison,
avg_loglik = loglik,
alpha_sum_mean = mean(rowSums(pred$alpha_predictions)),
alpha_sum_sd = sd(rowSums(pred$alpha_predictions))
)
cat("\nPrediction type:", pred_type, "\n")
cat("  MAE:", round(mae, 4), "\n")
cat("  RMSE:", round(rmse, 4), "\n")
cat("  Mean Aitchison distance:", round(aitchison, 4), "\n")
cat("  Avg log-likelihood:", round(loglik, 4), "\n")
}
# Cleanup
cleanup_distributed_forest(model)
cat("\nModel cleaned up.\n")
}
return(results)
}
visualize_results <- function(results) {
# Convert results to data frame
results_df <- do.call(rbind, lapply(names(results), function(name) {
r <- results[[name]]
data.frame(
config = r$config,
store_samples = r$store_samples,
method = r$method,
prediction_type = r$prediction_type,
train_time = r$train_time,
pred_time = r$pred_time,
mae = r$mae,
rmse = r$rmse,
mean_aitchison = r$mean_aitchison,
avg_loglik = r$avg_loglik,
alpha_sum_mean = r$alpha_sum_mean,
alpha_sum_sd = r$alpha_sum_sd,
stringsAsFactors = FALSE
)
}))
# Create comparison plots
par(mfrow = c(2, 3))
# 1. MAE comparison
barplot(
results_df$mae,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Mean Absolute Error",
ylab = "MAE",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 2. RMSE comparison
barplot(
results_df$rmse,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Root Mean Squared Error",
ylab = "RMSE",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 3. Aitchison distance
barplot(
results_df$mean_aitchison,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Mean Aitchison Distance",
ylab = "Aitchison Distance",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 4. Log-likelihood
barplot(
results_df$avg_loglik,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method, "\n",
results_df$prediction_type),
main = "Average Log-Likelihood",
ylab = "Log-Likelihood",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 5. Training time
barplot(
results_df$train_time,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method),
main = "Training Time",
ylab = "Seconds",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
# 6. Prediction time
barplot(
results_df$pred_time,
names.arg = paste0(results_df$store_samples, "\n",
results_df$method),
main = "Prediction Time",
ylab = "Seconds",
las = 2,
cex.names = 0.6,
col = rainbow(nrow(results_df))
)
par(mfrow = c(1, 1))
return(results_df)
}
# Generate data
cat("Generating data...\n")
data_sim <- simulate_dirichlet_data(n_samples = 1000, n_features = 10,
n_categories = 3, seed = 42)
data_split <- split_data(data_sim$X, data_sim$Y, train_ratio = 0.8)
# Run comparison
cat("\nStarting comparison...\n")
results <- compare_configurations(
data = data_split,
n_trees = 100,
n_cores = 3,
seed = 123
)
# Visualize results
cat("\nGenerating visualizations...\n")
results_df <- visualize_results(results)
# Print summary table
cat("\n========================================\n")
cat("SUMMARY TABLE\n")
cat("========================================\n")
print(results_df)
# Save results
write.csv(results_df, "dirichlet_forest_comparison.csv", row.names = FALSE)
cat("\nResults saved to 'dirichlet_forest_comparison.csv'\n")
cat("\n========================================\n")
cat("DETAILED ANALYSIS\n")
cat("========================================\n")
# Best configuration by metric
cat("\nBest configurations by metric:\n")
cat("Lowest MAE:", results_df$config[which.min(results_df$mae)],
"- Prediction:", results_df$prediction_type[which.min(results_df$mae)],
"- Value:", round(min(results_df$mae), 4), "\n")
cat("Lowest RMSE:", results_df$config[which.min(results_df$rmse)],
"- Prediction:", results_df$prediction_type[which.min(results_df$rmse)],
"- Value:", round(min(results_df$rmse), 4), "\n")
cat("Lowest Aitchison:", results_df$config[which.min(results_df$mean_aitchison)],
"- Prediction:", results_df$prediction_type[which.min(results_df$mean_aitchison)],
"- Value:", round(min(results_df$mean_aitchison), 4), "\n")
cat("Highest Log-Likelihood:", results_df$config[which.max(results_df$avg_loglik)],
"- Prediction:", results_df$prediction_type[which.max(results_df$avg_loglik)],
"- Value:", round(max(results_df$avg_loglik), 4), "\n")
# Compare mean vs alpha-derived predictions
cat("\n--- Mean vs Alpha-Derived Predictions ---\n")
for (config in unique(results_df$config)) {
config_results <- results_df[results_df$config == config, ]
cat("\nConfiguration:", config, "\n")
cat("  Mean prediction MAE:",
round(config_results$mae[config_results$prediction_type == "mean"], 4), "\n")
cat("  Alpha-derived MAE:",
round(config_results$mae[config_results$prediction_type == "alpha_derived"], 4), "\n")
cat("  Difference:",
round(config_results$mae[config_results$prediction_type == "mean"] -
config_results$mae[config_results$prediction_type == "alpha_derived"], 4), "\n")
}
# Compare store_samples modes
cat("\n--- Store Samples Comparison ---\n")
for (method in c("mom", "mle")) {
cat("\nMethod:", method, "\n")
false_results <- results_df[results_df$store_samples == FALSE &
results_df$method == method &
results_df$prediction_type == "mean", ]
true_results <- results_df[results_df$store_samples == TRUE &
results_df$method == method &
results_df$prediction_type == "mean", ]
cat("  store_samples = FALSE:\n")
cat("    MAE:", round(false_results$mae, 4), "\n")
cat("    Training time:", round(false_results$train_time, 2), "s\n")
cat("    Prediction time:", round(false_results$pred_time, 2), "s\n")
cat("  store_samples = TRUE:\n")
cat("    MAE:", round(true_results$mae, 4), "\n")
cat("    Training time:", round(true_results$train_time, 2), "s\n")
cat("    Prediction time:", round(true_results$pred_time, 2), "s\n")
cat("  Speed improvement (FALSE vs TRUE):",
round(true_results$pred_time / false_results$pred_time, 2), "x\n")
}
# Alpha parameter stability analysis
cat("\n--- Alpha Parameter Stability ---\n")
for (config in unique(results_df$config)) {
config_result <- results_df[results_df$config == config, ][1, ]
cat(config, ":\n")
cat("  Mean sum of alphas:", round(config_result$alpha_sum_mean, 2), "\n")
cat("  SD of alpha sums:", round(config_result$alpha_sum_sd, 2), "\n")
cat("  Coefficient of variation:",
round(config_result$alpha_sum_sd / config_result$alpha_sum_mean, 4), "\n\n")
}
library(DirichletForestParallel)
# Generate predictors
n <- 500
p <- 4
X <- matrix(rnorm(n * p), n, p)
# Generate Dirichlet responses
if (!requireNamespace("MCMCpack", quietly = TRUE)) {
install.packages("MCMCpack")
}
alpha <- c(2, 3, 4)
Y <- MCMCpack::rdirichlet(n, alpha)
# Fit a distributed Dirichlet Forest with 50 trees using 3 cores
df_par <- DirichletForest_distributed(X, Y, B = 50, n_cores = 3)
# Fit a distributed Dirichlet Forest with 50 trees using 3 cores
df_par <- DirichletForest_distributed(X, Y, B = 50, n_cores = 1)
# Predict on new data
X_test <- matrix(rnorm(10 * p), 10, p)
pred <- predict_distributed_forest(df_par, X_test)
pred
pred <- predict_distributed_forest(df_par, X_test)
pred
?DirichletForest_distributed
?predict_distributed_forest
?DirichletForest_distributed
.rs.restartR()
setwd("C:/Users/29827094/Documents/GitHub/DirichletForestParallel")
system("R CMD BUILD --binary .")
setwd("C:/Users/29827094/Documents/GitHub/DirichletForestParallel/")
system("R CMD BUILD --binary .")
# Generate data
setwd("C:/Users/29827094/Documents/GitHub/DirichletForestParallel")
# Build the binary ZIP without installing
system("R CMD BUILD --binary .")

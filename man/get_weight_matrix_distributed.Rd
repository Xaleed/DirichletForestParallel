% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dirichlet_forest.R
\name{get_weight_matrix_distributed}
\alias{get_weight_matrix_distributed}
\title{Get Weight Matrix for Distributed Forest}
\usage{
get_weight_matrix_distributed(distributed_forest, X_test)
}
\arguments{
\item{distributed_forest}{A distributed forest object with store_samples = TRUE}

\item{X_test}{Numeric matrix of test samples (m x p), where m is number of test samples.
Can also be a single vector or 1-row matrix for a single test sample.}
}
\value{
A list with:
\describe{
\item{weight_matrix}{Numeric matrix (m x n) where entry \link{i,j} is the weight of
training sample j for test sample i. Each row sums to 1.0}
\item{sample_indices}{Integer vector 1:n (all training sample indices in order)}
\item{Y_values}{Matrix of Y values for ALL training samples (n x k)}
}
}
\description{
Computes sample weights for multiple test observations using a distributed forest.
Each row of the output matrix contains weights for one test sample,
showing how much each training sample contributed to that prediction.
}
\details{
The weight matrix shows which training samples influenced each prediction.
Most weights will be zero; non-zero weights indicate training samples that
fell into the same leaf nodes as the test sample across the forest.

The predictions can be verified using matrix multiplication:
\code{predicted_Y = weight_matrix \%*\% Y_values}
}
\examples{
\donttest{
# Setup
library(DirichletForestParallel)
n <- 100
p <- 4
X <- matrix(rnorm(n * p), n, p)
Y <- MCMCpack::rdirichlet(n, c(2, 3, 4))
X_test <- matrix(rnorm(10 * p), 10, p)

# Build distributed forest with store_samples = TRUE
df <- DirichletForest_distributed(X, Y, B = 100, store_samples = TRUE, n_cores = 4)

# Get weight matrix for all test samples
weights <- get_weight_matrix_distributed(df, X_test)

# Examine structure
dim(weights$weight_matrix)  # 10 x 100 (10 test samples, 100 training samples)
cat("Weight matrix dimensions:", dim(weights$weight_matrix), "\n")

# Analyze weight sparsity
sparsity <- sum(weights$weight_matrix > 1e-10) / length(weights$weight_matrix)
cat("Proportion of non-zero weights:", round(sparsity, 3), "\n")

# Find most influential training samples for each test sample
for (i in 1:3) {
  cat("\n--- Test sample", i, "---\n")
  top_5 <- order(weights$weight_matrix[i, ], decreasing = TRUE)[1:5]
  print(data.frame(
    train_idx = top_5,
    weight = round(weights$weight_matrix[i, top_5], 4)
  ))
}

# Verify predictions match
pred <- predict_distributed_forest(df, X_test)
manual_pred <- weights$weight_matrix \%*\% weights$Y_values
cat("\nMax prediction difference:", 
    max(abs(pred$mean_predictions - manual_pred)), "\n")

# Verify each row sums to 1
row_sums <- rowSums(weights$weight_matrix)
cat("All row sums equal 1?", all(abs(row_sums - 1) < 1e-10), "\n")

# Analyze which training samples are most influential overall
col_sums <- colSums(weights$weight_matrix)
most_influential <- order(col_sums, decreasing = TRUE)[1:5]
cat("\nMost influential training samples overall:\n")
print(data.frame(
  train_idx = most_influential,
  total_weight = round(col_sums[most_influential], 2)
))

# Clean up
cleanup_distributed_forest(df)
}
}
